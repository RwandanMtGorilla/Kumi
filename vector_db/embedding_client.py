import time
import requests
from typing import List, Callable, Optional
from config.settings import settings
from config.embedding_config import EmbeddingConfig
import threading


class _OpenAIEmbeddingAPI:
    """OpenAI Embedding API å®¢æˆ·ç«¯ - å†…éƒ¨å•ä¾‹å®ç°"""

    def __init__(self, base_url: str = None, token: str = None, model: str = None, max_batch_size: int = 100):
        # åˆå§‹åŒ–embeddingé…ç½®
        embedding_config = EmbeddingConfig()
        provider_name, model_name = embedding_config.get_default_model()
        model_info = embedding_config.get_model_info(provider_name, model_name)

        # ä½¿ç”¨æ–°é…ç½®ç³»ç»Ÿè·å–é…ç½®,å…è®¸é€šè¿‡å‚æ•°è¦†ç›–
        self.base_url = (base_url or (model_info.get("api_base_url") if model_info else "")).rstrip('/')
        self.token = token or (model_info.get("api_key") if model_info else "")
        self.model = model or f"{provider_name},{model_name}"
        self.headers = {
            "Authorization": f"Bearer {self.token}",
            "Content-Type": "application/json"
        }
        self.max_batch_size = max_batch_size
        self.request_timeout = 120
        self.embedding_dim = None
        self._initialized = False
        self._lock = threading.Lock()

        print(f"ğŸ”„ OpenAIEmbeddingAPI å·²åˆ›å»º (model: {self.model}, batch_size: {self.max_batch_size})")

    def _lazy_init(self):
        """å»¶è¿Ÿåˆå§‹åŒ–,åœ¨ç¬¬ä¸€æ¬¡å®é™…è°ƒç”¨æ—¶åˆå§‹åŒ–"""
        if self._initialized:
            return

        with self._lock:
            if self._initialized:
                return

            print(f"ğŸ” é¦–æ¬¡è°ƒç”¨,æ­£åœ¨è·å– embedding ç»´åº¦...")
            # åœ¨ç¬¬ä¸€æ¬¡è°ƒç”¨æ—¶è·å–ç»´åº¦,è€Œä¸æ˜¯åœ¨åˆå§‹åŒ–æ—¶
            if self.embedding_dim is None:
                self.embedding_dim = self._get_actual_embedding_dimension()
            self._initialized = True
            print(f"âœ… OpenAIEmbeddingAPI åˆå§‹åŒ–å®Œæˆ,ç»´åº¦: {self.embedding_dim}")

    def set_batch_size(self, batch_size: int):
        """åŠ¨æ€è®¾ç½®æ‰¹å¤„ç†å¤§å°"""
        self._lazy_init()
        self.max_batch_size = batch_size
        print(f"ğŸ“¦ Embeddingæ‰¹å¤„ç†å¤§å°å·²è®¾ç½®ä¸º: {self.max_batch_size}")

    def test_connection(self):
        """
        æµ‹è¯•APIè¿æ¥(æ‰‹åŠ¨è°ƒç”¨) - é€šè¿‡å®é™…è°ƒç”¨embeddingæ¥å£æ¥æµ‹è¯•

        ä¸å†ä¾èµ–/healthç«¯ç‚¹ï¼Œè€Œæ˜¯ç›´æ¥æµ‹è¯•/v1/embeddingsç«¯ç‚¹
        è¿™æ ·å¯ä»¥åŒæ—¶éªŒè¯è¿æ¥æ€§å’Œè·å–embeddingç»´åº¦

        Returns:
            dict: {"success": bool, "message": str, "dimension": int}
        """
        try:
            print("ğŸ” æµ‹è¯•embedding APIè¿æ¥...")

            # ä½¿ç”¨ä¸€ä¸ªç®€å•çš„æµ‹è¯•æ–‡æœ¬
            test_text = "æµ‹è¯•è¿æ¥"

            # ç›´æ¥è°ƒç”¨embeddingæ¥å£è¿›è¡Œæµ‹è¯•
            test_response = self._encode_single_batch([test_text], get_dimension=True)

            # æ£€æŸ¥è¿”å›ç»“æœ
            if test_response and len(test_response) > 0:
                dimension = len(test_response[0])
                print(f"âœ… APIè¿æ¥æµ‹è¯•æˆåŠŸï¼Œembeddingç»´åº¦: {dimension}")
                return {
                    "success": True,
                    "message": f"APIè¿æ¥æˆåŠŸï¼Œembeddingç»´åº¦: {dimension}",
                    "dimension": dimension
                }
            else:
                print("âŒ APIè¿”å›äº†ç©ºç»“æœ")
                return {
                    "success": False,
                    "message": "APIè¿”å›äº†ç©ºç»“æœï¼Œè¯·æ£€æŸ¥æ¨¡å‹é…ç½®",
                    "dimension": None
                }

        except requests.exceptions.ConnectionError as e:
            # è¿æ¥é”™è¯¯ï¼ˆæ— æ³•è¿æ¥åˆ°æœåŠ¡å™¨ï¼‰
            error_msg = f"æ— æ³•è¿æ¥åˆ°embeddingæœåŠ¡ ({self.base_url}): {str(e)}"
            print(f"âŒ {error_msg}")
            return {
                "success": False,
                "message": error_msg,
                "dimension": None
            }
        except requests.exceptions.Timeout as e:
            # è¶…æ—¶é”™è¯¯
            error_msg = f"è¿æ¥è¶…æ—¶ (timeout={self.request_timeout}s)ï¼Œè¯·æ£€æŸ¥æœåŠ¡æ˜¯å¦æ­£å¸¸è¿è¡Œ: {str(e)}"
            print(f"âŒ {error_msg}")
            return {
                "success": False,
                "message": error_msg,
                "dimension": None
            }
        except requests.exceptions.HTTPError as e:
            # HTTPé”™è¯¯ï¼ˆ4xx, 5xxï¼‰
            error_msg = f"HTTPé”™è¯¯: {str(e)}"
            print(f"âŒ {error_msg}")
            return {
                "success": False,
                "message": error_msg,
                "dimension": None
            }
        except Exception as e:
            # å…¶ä»–æœªé¢„æœŸçš„é”™è¯¯
            error_msg = f"æµ‹è¯•è¿æ¥æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"
            print(f"âŒ {error_msg}")
            return {
                "success": False,
                "message": error_msg,
                "dimension": None
            }

    def _get_actual_embedding_dimension(self) -> int:
        """é€šè¿‡å®é™…è°ƒç”¨APIè·å–embeddingç»´åº¦"""
        try:
            print("ğŸ” æ­£åœ¨æ£€æµ‹embeddingç»´åº¦...")
            test_response = self._encode_single_batch(["æµ‹è¯•æ–‡æœ¬"], get_dimension=True)
            if test_response and len(test_response) > 0:
                actual_dim = len(test_response[0])
                print(f"âœ… æ£€æµ‹åˆ°embeddingç»´åº¦: {actual_dim}")
                return actual_dim
            else:
                print("âš ï¸ æ— æ³•æ£€æµ‹embeddingç»´åº¦ï¼Œä½¿ç”¨é»˜è®¤å€¼1024")
                return 1024
        except Exception as e:
            print(f"âš ï¸ æ£€æµ‹embeddingç»´åº¦æ—¶å‡ºé”™: {e}ï¼Œä½¿ç”¨é»˜è®¤å€¼1024")
            return 1024

    def encode_texts(self, texts: List[str]) -> List[List[float]]:
        """æ‰¹é‡ç¼–ç æ–‡æœ¬ä¸ºå‘é‡"""
        self._lazy_init()
        if not texts:
            return []

        all_embeddings = []
        total_batches = (len(texts) + self.max_batch_size - 1) // self.max_batch_size

        print(f"ğŸ“¦ å¼€å§‹æ‰¹é‡å‘é‡åŒ–: {len(texts)} ä¸ªæ–‡æœ¬ï¼Œåˆ†ä¸º {total_batches} ä¸ªæ‰¹æ¬¡")

        for i in range(0, len(texts), self.max_batch_size):
            batch_texts = texts[i:i + self.max_batch_size]
            batch_num = i // self.max_batch_size + 1

            print(f"   å¤„ç†æ‰¹æ¬¡ {batch_num}/{total_batches} ({len(batch_texts)} ä¸ªæ–‡æœ¬)")
            batch_embeddings = self._encode_single_batch(batch_texts)
            all_embeddings.extend(batch_embeddings)

            if i + self.max_batch_size < len(texts):
                time.sleep(0.2)

        print(f"âœ… æ‰¹é‡å‘é‡åŒ–å®Œæˆ: å…±å¤„ç† {len(all_embeddings)} ä¸ªå‘é‡")
        return all_embeddings

    def encode_texts_with_progress(self, texts: List[str],
                                   progress_callback: Optional[Callable[[int, int, str], None]] = None) -> List[
        List[float]]:
        """æ‰¹é‡ç¼–ç æ–‡æœ¬ä¸ºå‘é‡ï¼ˆå¸¦è¿›åº¦å›è°ƒçš„æ–°æ–¹æ³•ï¼‰"""
        self._lazy_init()
        if not texts:
            return []

        all_embeddings = []
        total_batches = (len(texts) + self.max_batch_size - 1) // self.max_batch_size

        # åˆå§‹è¿›åº¦å›è°ƒ
        if progress_callback:
            progress_callback(0, total_batches, f"å¼€å§‹å‘é‡åŒ– {len(texts)} ä¸ªæ–‡æœ¬ï¼Œåˆ†ä¸º {total_batches} ä¸ªæ‰¹æ¬¡")

        print(f"ğŸ“¦ å¼€å§‹æ‰¹é‡å‘é‡åŒ–: {len(texts)} ä¸ªæ–‡æœ¬ï¼Œåˆ†ä¸º {total_batches} ä¸ªæ‰¹æ¬¡")

        for i in range(0, len(texts), self.max_batch_size):
            batch_texts = texts[i:i + self.max_batch_size]
            batch_num = i // self.max_batch_size + 1

            # æ‰¹æ¬¡å¼€å§‹å›è°ƒ
            if progress_callback:
                progress_callback(batch_num - 1, total_batches,
                                  f"æ­£åœ¨å¤„ç†ç¬¬ {batch_num}/{total_batches} æ‰¹æ¬¡ ({len(batch_texts)} ä¸ªæ–‡æœ¬)")

            print(f"   å¤„ç†æ‰¹æ¬¡ {batch_num}/{total_batches} ({len(batch_texts)} ä¸ªæ–‡æœ¬)")

            start_time = time.time()
            batch_embeddings = self._encode_single_batch(batch_texts)
            end_time = time.time()

            all_embeddings.extend(batch_embeddings)

            # æ‰¹æ¬¡å®Œæˆå›è°ƒ
            if progress_callback:
                progress_callback(batch_num, total_batches,
                                  f"ç¬¬ {batch_num}/{total_batches} æ‰¹æ¬¡å®Œæˆ ({end_time - start_time:.2f}ç§’)")

            if i + self.max_batch_size < len(texts):
                time.sleep(0.2)

        print(f"âœ… æ‰¹é‡å‘é‡åŒ–å®Œæˆ: å…±å¤„ç† {len(all_embeddings)} ä¸ªå‘é‡")

        # æœ€ç»ˆå®Œæˆå›è°ƒ
        if progress_callback:
            progress_callback(total_batches, total_batches, f"å‘é‡åŒ–å®Œæˆï¼Œå…±å¤„ç† {len(all_embeddings)} ä¸ªå‘é‡")

        return all_embeddings

    def _encode_single_batch(self, texts: List[str], get_dimension: bool = False) -> List[List[float]]:
        """
        ç¼–ç å•ä¸ªæ‰¹æ¬¡çš„æ–‡æœ¬

        Args:
            texts: è¦ç¼–ç çš„æ–‡æœ¬åˆ—è¡¨
            get_dimension: æ˜¯å¦ç”¨äºè·å–ç»´åº¦ï¼ˆæµ‹è¯•è¿æ¥æ—¶ä½¿ç”¨ï¼‰ï¼Œä¸ºTrueæ—¶å¤±è´¥ä¼šæŠ›å‡ºå¼‚å¸¸

        Returns:
            å‘é‡åˆ—è¡¨

        Raises:
            å½“get_dimension=Trueä¸”å¤±è´¥æ—¶æŠ›å‡ºå¼‚å¸¸
        """
        payload = {
            "model": self.model,
            "input": texts,
            "encoding_format": "float"
        }

        max_retries = 5
        last_error = None

        for attempt in range(max_retries):
            try:
                start_time = time.time()
                response = requests.post(
                    f"{self.base_url}/v1/embeddings",
                    headers=self.headers,
                    json=payload,
                    timeout=self.request_timeout
                )
                end_time = time.time()

                if response.status_code == 200:
                    data = response.json()
                    embeddings = [item["embedding"] for item in data["data"]]
                    if not get_dimension:
                        print(f"      âœ… æ‰¹æ¬¡å®Œæˆ ({end_time - start_time:.2f}ç§’)")
                    return embeddings
                else:
                    error_msg = f"APIè¯·æ±‚å¤±è´¥: {response.status_code} - {response.text}"
                    last_error = Exception(error_msg)
                    if attempt == max_retries - 1:
                        # æœ€åä¸€æ¬¡é‡è¯•å¤±è´¥ï¼ŒæŠ›å‡ºå¼‚å¸¸
                        raise last_error
                    else:
                        print(f"      âš ï¸ {error_msg}, é‡è¯•ä¸­... ({attempt + 1}/{max_retries})")
                        time.sleep(2 ** attempt)

            except requests.exceptions.Timeout as e:
                last_error = e
                if attempt == max_retries - 1:
                    # æœ€åä¸€æ¬¡é‡è¯•å¤±è´¥ï¼ŒæŠ›å‡ºå¼‚å¸¸
                    raise requests.exceptions.Timeout("APIè¯·æ±‚è¶…æ—¶")
                else:
                    print(f"      âš ï¸ APIè¯·æ±‚è¶…æ—¶ï¼Œé‡è¯•ä¸­... ({attempt + 1}/{max_retries})")
                    time.sleep(2 ** attempt)
            except requests.exceptions.ConnectionError as e:
                # è¿æ¥é”™è¯¯é€šå¸¸ä¸éœ€è¦é‡è¯•ï¼Œç›´æ¥æŠ›å‡º
                last_error = e
                raise
            except requests.exceptions.RequestException as e:
                # å…¶ä»–requestsç›¸å…³é”™è¯¯
                last_error = e
                if attempt == max_retries - 1:
                    raise
                else:
                    print(f"      âš ï¸ è¯·æ±‚å¼‚å¸¸: {e}, é‡è¯•ä¸­... ({attempt + 1}/{max_retries})")
                    time.sleep(2 ** attempt)
            except Exception as e:
                # å…¶ä»–æœªé¢„æœŸçš„å¼‚å¸¸ï¼ˆå¦‚JSONè§£æé”™è¯¯ï¼‰
                last_error = e
                if attempt == max_retries - 1:
                    raise Exception(f"APIè¯·æ±‚å¼‚å¸¸: {e}")
                else:
                    print(f"      âš ï¸ APIè¯·æ±‚å¼‚å¸¸: {e}, é‡è¯•ä¸­... ({attempt + 1}/{max_retries})")
                    time.sleep(2 ** attempt)

        # å¦‚æœæ˜¯æµ‹è¯•è¿æ¥ï¼ˆget_dimension=Trueï¼‰ï¼Œå¤±è´¥æ—¶æŠ›å‡ºå¼‚å¸¸
        if get_dimension and last_error:
            print(f"      âŒ æ‰¹æ¬¡ç¼–ç å¤±è´¥")
            raise last_error

        # æ­£å¸¸å‘é‡åŒ–æµç¨‹å¤±è´¥æ—¶è¿”å›é›¶å‘é‡ï¼ˆå®¹é”™å¤„ç†ï¼‰
        print(f"      âŒ æ‰¹æ¬¡ç¼–ç å¤±è´¥ï¼Œè¿”å›é›¶å‘é‡")
        fallback_dim = getattr(self, 'embedding_dim', 1024)
        return [[0.0] * fallback_dim for _ in texts]


# æ¨¡å—çº§å•ä¾‹å®ä¾‹
_embedding_instance = None
_embedding_lock = threading.Lock()


class OpenAIEmbeddingAPI:
    """OpenAIEmbeddingAPI çš„ä»£ç†ç±»ï¼Œç¡®ä¿å§‹ç»ˆè¿”å›åŒä¸€ä¸ªå®ä¾‹"""

    def __new__(cls, *args, **kwargs):
        global _embedding_instance
        if _embedding_instance is None:
            with _embedding_lock:
                if _embedding_instance is None:
                    _embedding_instance = _OpenAIEmbeddingAPI(*args, **kwargs)
        return _embedding_instance
