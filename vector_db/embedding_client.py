import time
import requests
from typing import List, Callable, Optional
from config.settings import settings
from config.embedding_config import EmbeddingConfig
import threading


class _OpenAIEmbeddingAPI:
    """OpenAI Embedding API å®¢æˆ·ç«¯ - å†…éƒ¨å•ä¾‹å®ç°"""

    def __init__(self, base_url: str = None, token: str = None, model: str = None, max_batch_size: int = 100):
        # åˆå§‹åŒ–embeddingé…ç½®
        embedding_config = EmbeddingConfig()
        provider_name, model_name = embedding_config.get_default_model()
        model_info = embedding_config.get_model_info(provider_name, model_name)

        # ä½¿ç”¨æ–°é…ç½®ç³»ç»Ÿè·å–é…ç½®,å…è®¸é€šè¿‡å‚æ•°è¦†ç›–
        self.base_url = (base_url or (model_info.get("api_base_url") if model_info else "")).rstrip('/')
        self.token = token or (model_info.get("api_key") if model_info else "")
        self.model = model or f"{provider_name},{model_name}"
        self.headers = {
            "Authorization": f"Bearer {self.token}",
            "Content-Type": "application/json"
        }
        self.max_batch_size = max_batch_size
        self.request_timeout = 120
        self.embedding_dim = None
        self._initialized = False
        self._lock = threading.Lock()

        print(f"ğŸ”„ OpenAIEmbeddingAPI å·²åˆ›å»º (model: {self.model}, batch_size: {self.max_batch_size})")

    def _lazy_init(self):
        """å»¶è¿Ÿåˆå§‹åŒ–,åœ¨ç¬¬ä¸€æ¬¡å®é™…è°ƒç”¨æ—¶åˆå§‹åŒ–"""
        if self._initialized:
            return

        with self._lock:
            if self._initialized:
                return

            print(f"ğŸ” é¦–æ¬¡è°ƒç”¨,æ­£åœ¨è·å– embedding ç»´åº¦...")
            # åœ¨ç¬¬ä¸€æ¬¡è°ƒç”¨æ—¶è·å–ç»´åº¦,è€Œä¸æ˜¯åœ¨åˆå§‹åŒ–æ—¶
            if self.embedding_dim is None:
                self.embedding_dim = self._get_actual_embedding_dimension()
            self._initialized = True
            print(f"âœ… OpenAIEmbeddingAPI åˆå§‹åŒ–å®Œæˆ,ç»´åº¦: {self.embedding_dim}")

    def set_batch_size(self, batch_size: int):
        """åŠ¨æ€è®¾ç½®æ‰¹å¤„ç†å¤§å°"""
        self._lazy_init()
        self.max_batch_size = batch_size
        print(f"ğŸ“¦ Embeddingæ‰¹å¤„ç†å¤§å°å·²è®¾ç½®ä¸º: {self.max_batch_size}")

    def test_connection(self):
        """
        æµ‹è¯•APIè¿æ¥(æ‰‹åŠ¨è°ƒç”¨)

        Returns:
            dict: {"success": bool, "message": str, "dimension": int}
        """
        try:
            response = requests.get(f"{self.base_url}/health", timeout=10)
            if response.status_code == 200:
                health_status = response.text.strip('"')
                # è·å–ç»´åº¦
                dimension = self._get_actual_embedding_dimension()
                return {
                    "success": True,
                    "message": f"APIè¿æ¥æˆåŠŸ: {health_status}",
                    "dimension": dimension
                }
            else:
                return {
                    "success": False,
                    "message": f"APIå¥åº·æ£€æŸ¥å¤±è´¥: {response.status_code}",
                    "dimension": None
                }
        except Exception as e:
            return {
                "success": False,
                "message": f"APIè¿æ¥å¤±è´¥: {str(e)}",
                "dimension": None
            }

    def _get_actual_embedding_dimension(self) -> int:
        """é€šè¿‡å®é™…è°ƒç”¨APIè·å–embeddingç»´åº¦"""
        try:
            print("ğŸ” æ­£åœ¨æ£€æµ‹embeddingç»´åº¦...")
            test_response = self._encode_single_batch(["æµ‹è¯•æ–‡æœ¬"], get_dimension=True)
            if test_response and len(test_response) > 0:
                actual_dim = len(test_response[0])
                print(f"âœ… æ£€æµ‹åˆ°embeddingç»´åº¦: {actual_dim}")
                return actual_dim
            else:
                print("âš ï¸ æ— æ³•æ£€æµ‹embeddingç»´åº¦ï¼Œä½¿ç”¨é»˜è®¤å€¼1024")
                return 1024
        except Exception as e:
            print(f"âš ï¸ æ£€æµ‹embeddingç»´åº¦æ—¶å‡ºé”™: {e}ï¼Œä½¿ç”¨é»˜è®¤å€¼1024")
            return 1024

    def encode_texts(self, texts: List[str]) -> List[List[float]]:
        """æ‰¹é‡ç¼–ç æ–‡æœ¬ä¸ºå‘é‡"""
        self._lazy_init()
        if not texts:
            return []

        all_embeddings = []
        total_batches = (len(texts) + self.max_batch_size - 1) // self.max_batch_size

        print(f"ğŸ“¦ å¼€å§‹æ‰¹é‡å‘é‡åŒ–: {len(texts)} ä¸ªæ–‡æœ¬ï¼Œåˆ†ä¸º {total_batches} ä¸ªæ‰¹æ¬¡")

        for i in range(0, len(texts), self.max_batch_size):
            batch_texts = texts[i:i + self.max_batch_size]
            batch_num = i // self.max_batch_size + 1

            print(f"   å¤„ç†æ‰¹æ¬¡ {batch_num}/{total_batches} ({len(batch_texts)} ä¸ªæ–‡æœ¬)")
            batch_embeddings = self._encode_single_batch(batch_texts)
            all_embeddings.extend(batch_embeddings)

            if i + self.max_batch_size < len(texts):
                time.sleep(0.2)

        print(f"âœ… æ‰¹é‡å‘é‡åŒ–å®Œæˆ: å…±å¤„ç† {len(all_embeddings)} ä¸ªå‘é‡")
        return all_embeddings

    def encode_texts_with_progress(self, texts: List[str],
                                   progress_callback: Optional[Callable[[int, int, str], None]] = None) -> List[
        List[float]]:
        """æ‰¹é‡ç¼–ç æ–‡æœ¬ä¸ºå‘é‡ï¼ˆå¸¦è¿›åº¦å›è°ƒçš„æ–°æ–¹æ³•ï¼‰"""
        self._lazy_init()
        if not texts:
            return []

        all_embeddings = []
        total_batches = (len(texts) + self.max_batch_size - 1) // self.max_batch_size

        # åˆå§‹è¿›åº¦å›è°ƒ
        if progress_callback:
            progress_callback(0, total_batches, f"å¼€å§‹å‘é‡åŒ– {len(texts)} ä¸ªæ–‡æœ¬ï¼Œåˆ†ä¸º {total_batches} ä¸ªæ‰¹æ¬¡")

        print(f"ğŸ“¦ å¼€å§‹æ‰¹é‡å‘é‡åŒ–: {len(texts)} ä¸ªæ–‡æœ¬ï¼Œåˆ†ä¸º {total_batches} ä¸ªæ‰¹æ¬¡")

        for i in range(0, len(texts), self.max_batch_size):
            batch_texts = texts[i:i + self.max_batch_size]
            batch_num = i // self.max_batch_size + 1

            # æ‰¹æ¬¡å¼€å§‹å›è°ƒ
            if progress_callback:
                progress_callback(batch_num - 1, total_batches,
                                  f"æ­£åœ¨å¤„ç†ç¬¬ {batch_num}/{total_batches} æ‰¹æ¬¡ ({len(batch_texts)} ä¸ªæ–‡æœ¬)")

            print(f"   å¤„ç†æ‰¹æ¬¡ {batch_num}/{total_batches} ({len(batch_texts)} ä¸ªæ–‡æœ¬)")

            start_time = time.time()
            batch_embeddings = self._encode_single_batch(batch_texts)
            end_time = time.time()

            all_embeddings.extend(batch_embeddings)

            # æ‰¹æ¬¡å®Œæˆå›è°ƒ
            if progress_callback:
                progress_callback(batch_num, total_batches,
                                  f"ç¬¬ {batch_num}/{total_batches} æ‰¹æ¬¡å®Œæˆ ({end_time - start_time:.2f}ç§’)")

            if i + self.max_batch_size < len(texts):
                time.sleep(0.2)

        print(f"âœ… æ‰¹é‡å‘é‡åŒ–å®Œæˆ: å…±å¤„ç† {len(all_embeddings)} ä¸ªå‘é‡")

        # æœ€ç»ˆå®Œæˆå›è°ƒ
        if progress_callback:
            progress_callback(total_batches, total_batches, f"å‘é‡åŒ–å®Œæˆï¼Œå…±å¤„ç† {len(all_embeddings)} ä¸ªå‘é‡")

        return all_embeddings

    def _encode_single_batch(self, texts: List[str], get_dimension: bool = False) -> List[List[float]]:
        """ç¼–ç å•ä¸ªæ‰¹æ¬¡çš„æ–‡æœ¬"""
        payload = {
            "model": self.model,
            "input": texts,
            "encoding_format": "float"
        }

        max_retries = 5
        for attempt in range(max_retries):
            try:
                start_time = time.time()
                response = requests.post(
                    f"{self.base_url}/v1/embeddings",
                    headers=self.headers,
                    json=payload,
                    timeout=self.request_timeout
                )
                end_time = time.time()

                if response.status_code == 200:
                    data = response.json()
                    embeddings = [item["embedding"] for item in data["data"]]
                    if not get_dimension:
                        print(f"      âœ… æ‰¹æ¬¡å®Œæˆ ({end_time - start_time:.2f}ç§’)")
                    return embeddings
                else:
                    error_msg = f"APIè¯·æ±‚å¤±è´¥: {response.status_code} - {response.text}"
                    if attempt == max_retries - 1:
                        raise Exception(error_msg)
                    else:
                        print(f"      âš ï¸ {error_msg}, é‡è¯•ä¸­... ({attempt + 1}/{max_retries})")
                        time.sleep(2 ** attempt)

            except requests.exceptions.Timeout:
                if attempt == max_retries - 1:
                    raise Exception("APIè¯·æ±‚è¶…æ—¶")
                else:
                    print(f"      âš ï¸ APIè¯·æ±‚è¶…æ—¶ï¼Œé‡è¯•ä¸­... ({attempt + 1}/{max_retries})")
                    time.sleep(2 ** attempt)
            except Exception as e:
                if attempt == max_retries - 1:
                    raise Exception(f"APIè¯·æ±‚å¼‚å¸¸: {e}")
                else:
                    print(f"      âš ï¸ APIè¯·æ±‚å¼‚å¸¸: {e}, é‡è¯•ä¸­... ({attempt + 1}/{max_retries})")
                    time.sleep(2 ** attempt)

        print(f"      âŒ æ‰¹æ¬¡ç¼–ç å¤±è´¥ï¼Œè¿”å›é›¶å‘é‡")
        fallback_dim = getattr(self, 'embedding_dim', 1024)
        return [[0.0] * fallback_dim for _ in texts]


# æ¨¡å—çº§å•ä¾‹å®ä¾‹
_embedding_instance = None
_embedding_lock = threading.Lock()


class OpenAIEmbeddingAPI:
    """OpenAIEmbeddingAPI çš„ä»£ç†ç±»ï¼Œç¡®ä¿å§‹ç»ˆè¿”å›åŒä¸€ä¸ªå®ä¾‹"""

    def __new__(cls, *args, **kwargs):
        global _embedding_instance
        if _embedding_instance is None:
            with _embedding_lock:
                if _embedding_instance is None:
                    _embedding_instance = _OpenAIEmbeddingAPI(*args, **kwargs)
        return _embedding_instance
